{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 支持向量机方法的语音情感识别实现以及评估"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用Emo_DB数据库,柏林工业大学录制.\n",
    "分类如下:\n",
    "```\n",
    "letter\temotion (english)\tletter\temotion (german)\n",
    "A\tanger\tW\tÄrger (Wut)\n",
    "B\tboredom\tL\tLangeweile\n",
    "D\tdisgust\tE\tEkel\n",
    "F\tanxiety/fear\tA\tAngst\n",
    "H\thappiness\tF\tFreude\n",
    "S\tsadness\tT\tTrauer\n",
    "N = neutral version\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "EmoList = ['anger', 'boredom', 'disgust', 'anxiety/fear', 'happiness', 'sadness', 'neutarl']\n",
    "\n",
    "\n",
    "def getEmotion(fileName):\n",
    "    if 'A' in fileName:\n",
    "        return 'fear'\n",
    "    elif 'W' in fileName:\n",
    "        return 'anger'\n",
    "    elif 'L' in fileName:\n",
    "        return 'boredom'\n",
    "    elif 'F' in fileName:\n",
    "        return 'happy'\n",
    "    elif 'T' in fileName:\n",
    "        return 'sad'\n",
    "    elif 'E' in fileName:\n",
    "        return 'disgust'\n",
    "    elif 'N' in fileName:\n",
    "        return 'neutral'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "filePath = os.walk(r\"D:\\SpeechEmotionRecognition\\dataset\\Emo-DB\\wav\")\n",
    "fileList = list([i for i in filePath][0])[2:][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "EmoList = [getEmotion(i) for i in fileList]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "os.chdir(r\"D:\\SpeechEmotionRecognition\\dataset\\Emo-DB\\wav\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "data, sampling_rate = librosa.load(fileList[42], duration=3, offset=0.5)\n",
    "# data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "22050"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "def extract_mfcc(filename):\n",
    "    data, sampling_rate = librosa.load(filename, duration=3, offset=0.5)\n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=64)\n",
    "    mfcc_scaled = np.mean(mfccs.T, axis=0)\n",
    "    return mfcc_scaled"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "sequence = [extract_mfcc(i) for i in fileList]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-2.5866388e+02,  1.0037382e+02, -4.3144783e+01,  4.4948952e+01,\n       -9.4050846e+00,  1.4938450e+00, -1.1602770e+01,  9.4904429e-01,\n       -2.0080004e+01, -1.4023942e+01, -2.2404554e+00, -1.2222795e+01,\n       -5.8485401e-01, -1.5121354e+01,  4.7117958e+00, -2.2433913e+00,\n       -5.7632809e+00, -2.1108053e+00, -4.4906902e+00, -1.5633948e+00,\n       -2.2546792e+00,  2.1571879e+00, -6.4659443e+00, -2.2059062e+00,\n       -5.9675655e+00, -3.8036745e+00, -1.7230661e+00,  1.0110145e-01,\n        2.2422442e+00, -2.4449635e+00,  2.9775691e+00, -2.1144652e+00,\n        1.4298250e-01,  1.5012416e-01,  1.8711941e-01,  2.0893056e+00,\n        2.6053292e-01,  1.4545770e+00,  1.2673495e+00,  3.5544436e+00,\n        1.7999094e+00,  5.3344727e+00,  4.9093075e+00,  3.3470671e+00,\n        5.0946608e+00,  4.1163092e+00,  4.6195498e+00,  3.5717468e+00,\n        2.6710844e+00,  1.1702039e+00,  1.4572349e+00,  2.3130095e+00,\n        3.0296566e+00,  1.5378088e+00,  5.6293267e-01,  6.5076953e-01,\n        1.3339015e+00,  1.5151588e+00, -2.0293958e-01,  8.5190243e-01,\n        4.1982859e-01,  4.9650332e-01,  2.8618413e-01,  5.8556879e-01],\n      dtype=float32)"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence[42]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "data": {
      "text/plain": "(535, 64)"
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(sequence)\n",
    "x.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "data": {
      "text/plain": "(535,)"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def idx_y(type):\n",
    "    dict = {\n",
    "        'fear': 0,\n",
    "        'anger': 1,\n",
    "        'boredom': 2,\n",
    "        'happy': 3,\n",
    "        'sad': 4,\n",
    "        'disgust': 5,\n",
    "        'neutral': 6\n",
    "    }\n",
    "    return dict.get(type)\n",
    "\n",
    "\n",
    "y = [idx_y(elem) for elem in EmoList]\n",
    "y = np.array(y)\n",
    "y.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "data": {
      "text/plain": "SVC(C=1024)",
      "text/html": "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1024)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1024)</pre></div></div></div></div></div>"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC(kernel='rbf', C=1024,decision_function_shape='ovr')\n",
    "model.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9919786096256684"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "def show_accuracy(a, b):\n",
    "    acc = a == b\n",
    "    return np.mean(acc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7701863354037267"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy = model.predict(x_test)\n",
    "show_accuracy(yy, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "array([6, 4, 1, 1, 6, 2, 5, 4, 4, 5, 1, 5, 4, 3, 0, 1, 6, 0, 5, 2, 6, 1,\n       5, 6, 3, 1, 6, 2, 2, 6, 0, 2])"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[:32])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 在取得MFCC特征之前进行划分，从直观上来判断模型的效果\n",
    "手动测试，直觉上感觉90%的正确率可能有错误"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "data": {
      "text/plain": "array([3, 6, 1, 3, 6, 4, 1, 1, 0, 3, 2, 6, 4, 1, 0, 3, 6, 4, 1, 1, 3, 3,\n       2, 6, 1, 3, 2, 6, 4, 1, 1, 0, 2, 6, 4, 1, 6, 4, 1, 2, 6, 4, 1, 0,\n       5, 6, 6, 1, 1, 0, 3, 2, 6, 1, 1, 0, 0, 3, 2, 6, 4, 1, 3, 2, 6, 4,\n       1, 3, 2, 6, 4, 1, 3, 2, 6, 4, 4, 1, 0, 3, 3, 2, 6, 1, 3, 2, 6, 4,\n       1, 3, 2, 6, 4, 1, 0, 3, 2, 6, 4, 1, 1, 0, 3, 2, 6, 4, 1, 5, 3, 6,\n       1, 5, 5, 2, 1, 3, 2, 6, 1, 5, 2, 6, 4, 1, 1, 5, 6, 4, 1, 1, 5, 6,\n       1, 6, 4, 1, 1, 5, 3, 3, 2, 6, 4, 1, 5, 6, 1, 0, 6, 1, 0, 6, 1, 0,\n       3, 2, 6, 1, 3, 6, 1, 1, 0, 2, 4, 1, 0, 0, 2, 4, 1, 0, 5, 3, 2, 0,\n       2, 6, 1, 2, 4, 1, 0, 2, 1, 3, 2, 1, 0, 0, 2, 6, 1, 5, 3, 2, 6, 4,\n       1, 0, 3, 6, 1, 0, 3, 3, 2, 6, 4, 1, 0, 2, 4, 1, 0, 5, 3, 2, 6, 1,\n       0, 3, 6, 4, 1, 3, 2, 6, 4, 1, 1, 0, 3, 2, 6, 4, 1, 0, 0, 2, 6, 4,\n       1, 3, 2, 6, 1, 0, 5, 6, 1, 1, 1, 0, 2, 6, 4, 1, 0, 2, 1, 4, 1, 0,\n       5, 3, 6, 1, 1, 1, 2, 4, 0, 4, 1, 0, 2, 1, 0, 5, 5, 3, 2, 6, 1, 0,\n       5, 3, 2, 6, 4, 1, 0, 3, 2, 4, 1, 0, 5, 2, 6, 4, 1, 1, 3, 2, 6, 4,\n       1, 0, 5, 3, 2, 6, 1, 3, 2, 6, 1, 0, 5, 3, 2, 6, 4, 1, 0, 5, 3, 3,\n       2, 6, 1, 5, 3, 2, 6, 1, 1, 0, 0, 5, 6, 1, 1, 0, 5, 3, 2, 6, 4, 1,\n       1, 0, 5, 2, 4, 4, 1, 1, 0, 0, 3, 3, 2, 6, 4, 4, 1, 1, 0, 5, 3, 2,\n       2, 6, 4, 1, 0, 5, 3, 3, 6, 1, 0, 3, 6, 4, 1, 1, 0, 5, 2, 4, 1, 0,\n       5, 3, 2, 4, 1, 1, 0, 5, 2, 6, 4, 1, 5, 3, 2, 6, 1, 0, 5, 2, 6, 4,\n       1, 1, 0, 0, 3, 6, 1, 1, 5, 3, 2, 6, 1, 0, 5, 3, 3, 2, 6, 5, 2, 6,\n       1, 0, 2, 6, 4, 1, 1, 0, 2, 6, 4, 1, 1, 0, 3, 2, 6, 4, 1, 0, 2, 6,\n       6, 1, 5, 3, 2, 6, 4, 1, 5, 5, 2, 6, 4, 1, 0, 5, 3, 2, 2, 6, 4, 1,\n       1, 0, 5, 3, 2, 4, 1, 1, 5, 3, 3, 2, 2, 6, 4, 1, 0, 5, 3, 2, 2, 4,\n       1, 1, 0, 5, 3, 2, 1, 0, 5, 3, 3, 2, 6, 4, 1, 0, 5, 3, 2, 2, 1, 0,\n       5, 3, 2, 4, 4, 1, 1])"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.array(fileList)\n",
    "np.array(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(np.array(fileList), np.array(y), train_size=0.7)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "x_train = [extract_mfcc(i) for i in x_train]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C=64)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [
    "x_test = [extract_mfcc(i) for i in x_test]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "res = model.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "(161,)"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9254658385093167"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_accuracy(res, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "array([5, 3, 1, 4, 1, 1, 2, 0, 1, 4, 6, 6, 0, 3, 2, 4, 0, 5, 4, 3, 0, 4,\n       4, 3, 5, 1, 5, 2, 2, 1, 1, 3])"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:32]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "data": {
      "text/plain": "array([5, 3, 1, 5, 1, 1, 2, 0, 1, 4, 6, 6, 0, 3, 2, 4, 0, 5, 4, 3, 0, 4,\n       4, 3, 5, 1, 5, 2, 2, 1, 1, 1])"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:32]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9254658385093167\n"
     ]
    }
   ],
   "source": [
    "li = []\n",
    "for i,j in zip(res,y_test):\n",
    "    li.append(i==j)\n",
    "print(sum(li)/len(li))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
